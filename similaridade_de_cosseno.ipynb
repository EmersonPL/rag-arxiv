{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install python-dotenv\n",
    "!pip install python-decouple\n",
    "# !pip install --upgrade genai\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkyGHVbtaRDF",
    "outputId": "787d6f07-edbc-4010-fba2-0826c7935123"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Collecting python-decouple\n",
      "  Downloading python_decouple-3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Downloading python_decouple-3.8-py3-none-any.whl (9.9 kB)\n",
      "Installing collected packages: python-decouple\n",
      "Successfully installed python-decouple-3.8\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from decouple import config\n",
    "from dotenv import load_dotenv\n"
   ],
   "metadata": {
    "id": "N5n35sulPjYO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from decouple import config\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "def generate_embeddings(text: str) -> list[float] | None:\n",
    "    api_key = config(\"GEMINI_API_KEY\")\n",
    "\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    result = genai.embed_content(\n",
    "        model=config(\"EMBEDDINGS_MODEL\"),\n",
    "        content=text,\n",
    "    )\n",
    "    embeddings = result.get(\"embedding\")\n",
    "\n",
    "    return embeddings"
   ],
   "metadata": {
    "id": "dBA8elPnPtkJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def similaridade_de_cosseno(texto1: str, texto2: str) -> float:\n",
    "\n",
    "    embeddings1 = generate_embeddings(texto1)\n",
    "    embeddings2 = generate_embeddings(texto2)\n",
    "\n",
    "    if embeddings1 is None or embeddings2 is None:\n",
    "        raise ValueError(\"Erro ao gerar embeddings para os textos.\")\n",
    "\n",
    "    similaridade = cosine_similarity([embeddings1], [embeddings2])\n",
    "\n",
    "    return similaridade[0][0]"
   ],
   "metadata": {
    "id": "WF6l22BMPwCn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yj132VDsxJb5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "834e6fc6-123d-4d1d-ecc8-adfa00461caf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Similaridade de Consenso: 0.8207\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso da função\n",
    "texto1 = \"Yes, passive acoustic mapping (PAM) is a promising tool for monitoring acoustic cavitation activities in ultrasound therapy.  It allows continuous monitoring without interrupting therapeutic pulses and has shown efficacy in various ultrasound treatments.  While time exposure acoustics (TEA) is efficient, it has limitations in spatial resolution and artifact suppression. Data-adaptive beamformers improve image quality but are computationally expensive.  A deep beamformer approach offers a significant reduction in computational cost while maintaining image quality comparable to data-adaptive methods.\"\n",
    "texto2 = \"Passive acoustic mapping (PAM) is a promising tool for monitoring acoustic cavitation activities in ultrasound therapy applications.\"\n",
    "\n",
    "similaridade = similaridade_de_cosseno(texto1, texto2)\n",
    "print(f\"Similaridade de cosseno: {similaridade:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "1: Os vetores são idênticos (ou seja, a direção é exatamente a mesma).\n",
    "0: Não há similaridade (os vetores são ortogonais, ou seja, não têm correlação).\n",
    "-1: Os vetores são opostos (ou seja, estão em direções opostas).\n",
    "```\n"
   ],
   "metadata": {
    "id": "HHzRXSS8esRo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "What important role does private inference (PI) play?\n",
    "```\n",
    "# Resposta trabalho\n",
    "\n",
    "Based on the provided text, private inference (PI) plays an important role in protecting the privacy of agent evidence in collective decision-making.  The direct sharing of raw evidence leads to participants' preference leakage, so PI methods are necessary to prevent this.  The paper describes a privacy-preserving distributed credible evidence fusion algorithm (PCEF) that uses PI to guarantee evidence privacy and prevent raw evidence from being inferred.\n",
    "\n",
    "# Pergunta tirada do artigo TRUNCFORMER: PRIVATE LLM INFERENCE USING ONLY TRUNCATIONS`\n",
    "\n",
    "Private inference (PI) plays an important role by enabling machine learning models to make inferences on sensitive or private data without revealing this information. This is crucial for ensuring data privacy and security in applications where the protection of personal information is essential, such as in financial services, healthcare, and other sectors dealing with confidential data.\n",
    "```\n",
    "\n",
    "Similaridade de Cosseno: 0.7635\n"
   ],
   "metadata": {
    "id": "XVGfNe8AGLT9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the promising strategy for teaching robots a wide range of complex skills that recent works have demonstrated?\n",
    "```\n",
    "# Resposta trabalho\n",
    "\n",
    "Recent work has demonstrated that a promising strategy for teaching robots a wide range of complex skills is to use autoregressive generative pre-training on latent motion token sequences to learn motion priors from videos, followed by co-fine-tuning on action-labeled data for robot control.\n",
    "\n",
    "# Pergunta tirada do artigo Environment Curriculum Generation\n",
    "via Large Language Models\n",
    "\n",
    "Recent works have demonstrated that a promising strategy for teaching robots a wide range of complex skills is to train them on a curriculum of progressively more challenging environments.\n",
    "```\n",
    "\n",
    "Similaridade de Cosseno: 0.7110"
   ],
   "metadata": {
    "id": "be8VxIfHKnY-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Randomized rounding is a technique originally used for what?\n",
    "```\n",
    "# Resposta trabalho\n",
    "\n",
    "The provided text states that randomized rounding was originally a technique used for  achieving performative stability within the Repeated Risk Minimization (RRM) framework.\n",
    "\n",
    "# Pergunta tirada do artigo Randomized Rounding Approaches to Online\n",
    "Allocation, Sequencing, and Matching\n",
    "\n",
    "Randomized rounding is a technique originally used to approximate hard offline discrete optimization problems from a mathematical programming relaxation.\n",
    "```\n",
    "\n",
    "Similaridade de Cosseno: 0.7517"
   ],
   "metadata": {
    "id": "Yb_xDIu-hpUJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is a fundamental component of transformers?\n",
    "```\n",
    "# Resposta trabalho\n",
    "\n",
    "Based on the provided text, the main components of transformers are the encoder and the decoder.  These are stacked multiple times.  The encoder embeds a sentence into a set of numbers, while the decoder generates text based on the embedding of an input sentence.  Another important component is the multi-head attention mechanism, which computes similarity scores between words in a sentence.\n",
    "\n",
    "# Pergunta tirada do artigo THE ASYMPTOTIC BEHAVIOR OF ATTENTION IN TRANSFORMERS\n",
    "\n",
    "A key component of transformers is the attention mechanism orchestrating how each token influences the propagation of every other token through a transformer.\n",
    "```\n",
    "\n",
    "Similaridade de Cosseno: 0.7983"
   ],
   "metadata": {
    "id": "8XnmGmoF7yQe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is Truck Attention-QMIX (TA-QMIX)?\n",
    "```\n",
    "# Resposta trabalho\n",
    "\n",
    "Truck Attention-QMIX (TA-QMIX) is a Multi-Agent Deep Reinforcement Learning framework for efficient online decision policy training in truck platooning coordination.  It uses an attention mechanism to improve the representation of truck fuel gains and delay times, providing explicit cooperation information during training to encourage cooperation between trucks.  The framework uses centralized training and distributed execution, allowing trucks to make online decisions using only local information.  In experiments with 5,000 trucks, it achieved an average fuel savings of 19.17% with an average delay of only 9.57 minutes per truck and a decision time of 0.001 seconds.\n",
    "\n",
    "# Pergunta tirada do artigo Multi-Agent Deep Reinforcement Learning for\n",
    "Distributed and Autonomous Platoon Coordination via Speed-regulation over Large-scale Transportation Networks\n",
    "\n",
    "Truck Attention-QMIX (TA-QMIX) is a deep reinforcement learning multi-agent framework developed to solve the problem of truck platoon coordination in large-scale transportation networks. The main objective is to optimize overall transportation efficiency by promoting cooperation among trucks and balancing fuel savings with delays in departure times and speed.\n",
    "```\n",
    "\n",
    "Similaridade de Cosseno: 0.9537"
   ],
   "metadata": {
    "id": "ONSaJ87gZZhM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Is passive acoustic mapping (PAM) a promising tool\n",
    "```\n",
    "# Resposta trabalho\n",
    "\n",
    "Yes, passive acoustic mapping (PAM) is a promising tool for monitoring acoustic cavitation activities in ultrasound therapy.  It allows continuous monitoring without interrupting therapeutic pulses and has shown efficacy in various ultrasound treatments.  While time exposure acoustics (TEA) is efficient, it has limitations in spatial resolution and artifact suppression. Data-adaptive beamformers improve image quality but are computationally expensive.  A deep beamformer approach offers a significant reduction in computational cost while maintaining image quality comparable to data-adaptive methods.\n",
    "\n",
    "# Pergunta tirada do artigo Switchable deep beamformer for high-quality and real-time passive acoustic mapping\n",
    "\n",
    "Passive acoustic mapping (PAM) is a promising tool for monitoring acoustic cavitation activities in ultrasound therapy applications.\n",
    "```\n",
    "\n",
    "Similaridade de Cosseno: 0.8207"
   ],
   "metadata": {
    "id": "zT6VY33xa1C4"
   }
  }
 ]
}
